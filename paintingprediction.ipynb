{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "paintingprediction.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VO_NevbpNsgN"
      },
      "source": [
        "##This notebook contains the Naive CNN baseline and the LSTM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AckNJkaQTiFT"
      },
      "source": [
        "!pip install tensorflow\n",
        "import tensorflow as tf\n",
        "!pip install tensorflow_hub\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "import pathlib\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import random\n",
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v3bAUqHT2hJ"
      },
      "source": [
        "\n",
        "with open('phillips2.csv') as f:\n",
        "    lots = [{k: v for k, v in row.items()}\n",
        "        for row in csv.DictReader(f, skipinitialspace=True)]\n",
        "\n",
        "random.shuffle(lots)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROpCeGOsfvq9"
      },
      "source": [
        "#m = 8000 #Restricted dataset for colab run\n",
        "#lots = lots[:m]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eW_MtFbrDvj-"
      },
      "source": [
        "\"\"\" #If want to restrict to only expensive lots, as Verge & Singal did\n",
        "i = 0\n",
        "expensivelots = []\n",
        "for lot in lots:\n",
        "  if float(lot['price']) > 40000:\n",
        "    expensivelots.append(lot)\n",
        "    i += 1\n",
        "print(i)\n",
        "lots = expensivelots"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWRQmsmLPzJ0"
      },
      "source": [
        "###Preprocessing for Naive CNN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_ugjY5LUc9e"
      },
      "source": [
        "m = len(lots)\n",
        "#m = 5000 #for colab run\n",
        "images = np.empty((m, 224, 224, 3)) \n",
        "prices = np.empty((m))\n",
        "\n",
        "i = 0\n",
        "for lot in lots[:m]: \n",
        "  j = i # index to use for accessing price\n",
        "  try:\n",
        "    image = tf.image.decode_jpeg(requests.get(lot[\"imageurl\"]).content, channels=3)\n",
        "    lastimage = image\n",
        "  except:\n",
        "    image = lastimage\n",
        "    j -= 1 # going to use price from LAST image\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  image = tf.image.resize(image, [224, 224])\n",
        "  price = float(lot[\"price\"])\n",
        "\n",
        "  images[i,:,:,:] = image[:,:,:]\n",
        "  prices[j] = price\n",
        "  if i % 200 == 0:\n",
        "    print(i)\n",
        "  i += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25rcsDwLkDsH",
        "outputId": "07c66bfa-568b-46ca-8767-54aafda21168",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "fails = 0\n",
        "for lot in lots:\n",
        "  try:\n",
        "    int(lot['day'])\n",
        "    int(lot['month'])\n",
        "    int(lot['year'])\n",
        "  except:\n",
        "    print(lot)\n",
        "    lots.remove(lot)\n",
        "    fails += 1\n",
        "print(fails)\n",
        "print(len(lots))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "23825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o17N4iqIjvSH"
      },
      "source": [
        "###Random price selection MAPE (Baseline, to compare with Naive CNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qvu-QlkUjt8s"
      },
      "source": [
        "def randomselect(k, n, lots):\n",
        "  #MIGHT RETURN NONE!\n",
        "\n",
        "  idx = random.randint(n+100, len(lots)-100)\n",
        "  topredict = lots[idx]\n",
        "\n",
        "  guess= random.randint(100, len(lots)-100)\n",
        "  guessed = lots[guess]\n",
        "\n",
        "  mape = 100 * abs(float(topredict['price']) - float(guessed['price'])) / float(topredict['price'])\n",
        "  squarederror = abs(float(topredict['price']) - float(guessed['price'])) ** 2\n",
        "\n",
        "  return squarederror\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1Cj-fk7juPW",
        "outputId": "5b00302a-b077-44f6-e646-707e4b898e43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "m = 1000000\n",
        "sum = 0\n",
        "for i in range(m):\n",
        "  error = randomselect(0, 0, lots)\n",
        "  sum += error\n",
        "avgerror = sum / m\n",
        "avgerror = np.sqrt(avgerror)\n",
        "\n",
        "print(avgerror)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1570903.203739467\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0kiKdvwVlZK"
      },
      "source": [
        "print(images)\n",
        "print(prices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NELwl8LnU07J"
      },
      "source": [
        "m = len(lots)\n",
        "\n",
        "train_size = int(0.7 * m)\n",
        "val_size = int(0.15 * m)\n",
        "test_size = int(0.15 * m)\n",
        "\n",
        "img_train = images[:train_size,:,:,:]\n",
        "img_val = images[train_size:train_size + val_size,:,:,:]\n",
        "img_test = images[train_size + val_size:,:,:,:]\n",
        "\n",
        "label_train = prices[:train_size]\n",
        "label_val = prices[train_size:train_size + val_size]\n",
        "label_test = prices[train_size + val_size:]\n",
        "\n",
        "print(img_train.shape)\n",
        "print(label_train.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uda57NjyfBN"
      },
      "source": [
        "###Naive CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdfKi0KM4cAg"
      },
      "source": [
        "pretrained\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt5s3SfDWIhA"
      },
      "source": [
        "input_shape = [224, 224, 3]\n",
        "input = tf.keras.Input(input_shape)\n",
        "\n",
        "restransfer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/resnet_50/feature_vector/1\", trainable=False)(input)\n",
        "d1 = tf.keras.layers.Dense(128, activation=\"tanh\", trainable=True, kernel_initializer=tf.keras.initializers.GlorotNormal, kernel_regularizer='l2')(restransfer)\n",
        "dr1 = tf.keras.layers.Dropout(.2)(d1)\n",
        "d2 = tf.keras.layers.Dense(32, activation=\"tanh\", trainable=True, kernel_initializer=tf.keras.initializers.GlorotNormal, kernel_regularizer='l2')(dr1)\n",
        "dr2 = tf.keras.layers.Dropout(.2)(d2)\n",
        " # inputs size (None, 224, 224, 3) ; outputs size (128)\n",
        "\n",
        "\n",
        "\n",
        "prediction = tf.keras.layers.Dense(1, activation=\"relu\", trainable=True, kernel_initializer=tf.keras.initializers.GlorotNormal)(dr2)\n",
        "naivecnn = tf.keras.Model(inputs=[input], outputs=prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNYVlMj94fKA"
      },
      "source": [
        "vanilla"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miD37z3E4gld"
      },
      "source": [
        "input_shape = [224, 224, 3]\n",
        "input = tf.keras.Input(input_shape)\n",
        "\n",
        "cnn = tf.keras.Sequential()\n",
        "cnn.add(tf.keras.layers.Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "cnn.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "cnn.add(tf.keras.layers.Conv2D(64, (5, 5), activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "cnn.add(tf.keras.layers.Dense(1000, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "\n",
        "feature = cnn(input)\n",
        "prediction = tf.keras.layers.Dense(1, activation=\"relu\", trainable=True)(feature)\n",
        "naivecnn = tf.keras.Model(inputs=[input], outputs=prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjWTgPC9Wdcm"
      },
      "source": [
        "tf.keras.backend.set_epsilon(1e-05)\n",
        "\n",
        "naivecnn.compile(loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.MeanAbsolutePercentageError()], optimizer=keras.optimizers.Adam(learning_rate=.00001, clipvalue = 1))\n",
        "naivecnn.summary()\n",
        "\n",
        "assert not np.any(np.isnan(img_train))\n",
        "assert not np.any(np.isnan(label_train))\n",
        "\n",
        "history = naivecnn.fit([img_train], label_train, epochs=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nz6-g2mWgoP"
      },
      "source": [
        "naivecnn.evaluate([img_test], label_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtdf--5EyxT4"
      },
      "source": [
        "#LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbqhqyvDy0fm"
      },
      "source": [
        "n =  #sequence Length\n",
        "m = #number of sequences to generate\n",
        "\n",
        "\n",
        "\n",
        "lots = sorted(lots, key=lambda lot: lot['day'])\n",
        "lots = sorted(lots, key=lambda lot: lot['month'])\n",
        "lots = sorted(lots, key=lambda lot: lot['year'])\n",
        "\n",
        "\n",
        "topred = np.zeros((m, 224, 224, 3))\n",
        "lastn = np.zeros((m, n, 224, 224, 3))\n",
        "lastnprices = np.zeros((m, n))\n",
        "labels = np.zeros((m))\n",
        "\n",
        "\n",
        "\n",
        "j = 0\n",
        "while j < m:\n",
        "\n",
        "  idx = random.randint(n, len(lots))\n",
        "  topredict = lots[idx]\n",
        "  \n",
        "  lastnlots = lots[idx-n : idx]\n",
        "\n",
        "  \n",
        "  try:\n",
        "    predimg = tf.image.decode_jpeg(requests.get(topredict[\"imageurl\"]).content, channels=3)\n",
        "    lastimage = predimg\n",
        "  except:\n",
        "    continue\n",
        "  predimg = tf.image.convert_image_dtype(predimg, tf.float32)\n",
        "  predimg = tf.image.resize(predimg, [224, 224])\n",
        "  topred[j,:,:,:] = predimg[:,:,:]\n",
        "\n",
        "  labels[j] = topredict[\"price\"]\n",
        "\n",
        "  k=0\n",
        "  for lot in lastnlots:\n",
        "\n",
        "    \n",
        "    try:\n",
        "      lotimg = tf.image.decode_jpeg(requests.get(lot[\"imageurl\"]).content, channels=3)\n",
        "      lastimage = lotimg\n",
        "    except:\n",
        "      lotimg = lastimage\n",
        "    lotimg = tf.image.convert_image_dtype(lotimg, tf.float32)\n",
        "    lotimg = tf.image.resize(lotimg, [224, 224])   \n",
        "    lastn[j,k,:,:,:] = lotimg[:,:,:]\n",
        "    \n",
        "    lastnprices[j,k] = lot[\"price\"]\n",
        "\n",
        "    k += 1\n",
        "\n",
        "\n",
        "\n",
        "  j += 1\n",
        "  if j % 10 == 0:\n",
        "    print(str(j) + ' training examples created')\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vHav-RLRAQb"
      },
      "source": [
        "train_size = int(0.7 * m)\n",
        "val_size = int(0.15 * m)\n",
        "test_size = int(0.15 * m)\n",
        "\n",
        "\n",
        "topred_train = topred[:train_size,:,:,:]\n",
        "topred_val = topred[train_size:train_size + val_size,:,:,:]\n",
        "topred_test = topred[train_size + val_size:,:,:,:]\n",
        "\n",
        "lastn_train = lastn[:train_size,:,:,:,:]\n",
        "lastn_val = lastn[train_size:train_size + val_size,:,:,:,:]\n",
        "lastn_test = lastn[train_size + val_size:,:,:,:,:]\n",
        "\n",
        "price_train = lastnprices[:train_size,:]\n",
        "price_val = lastnprices[train_size:train_size + val_size,:]\n",
        "price_test = lastnprices[train_size + val_size:,:]\n",
        "\n",
        "label_train = labels[:train_size]\n",
        "label_val = labels[train_size:train_size + val_size]\n",
        "label_test = labels[train_size + val_size:]\n",
        "\n",
        "print(lastn_train.shape)\n",
        "print(label_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ap0Ra_QAc_T"
      },
      "source": [
        "##Create LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWwDqVaCBts2"
      },
      "source": [
        "topred_shape = [224, 224, 3]\n",
        "lastn_shape = [n, 224, 224, 3]\n",
        "price_shape = [n]\n",
        "topred_input = tf.keras.Input(topred_shape)\n",
        "lastn_input = tf.keras.Input(lastn_shape)\n",
        "price_input = tf.keras.Input(price_shape)\n",
        "\n",
        "cnn = tf.keras.Sequential()\n",
        "cnn.add(tf.keras.layers.Conv2D(8, kernel_size=(5, 5), strides=(1, 1),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "cnn.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "cnn.add(tf.keras.layers.Conv2D(16, (5, 5), activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "cnn.add(tf.keras.layers.Dense(1000, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "\n",
        "L1_layer = tf.keras.layers.Lambda(lambda tensors:tf.math.abs(tensors[0] - tensors[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfkE5OVVAenj"
      },
      "source": [
        "\n",
        "\n",
        "encoded_topred = cnn(topred_input)\n",
        "\n",
        "for i in range(n):\n",
        "  encoded_pastlot = cnn(lastn_input[:,i,:,:,:])\n",
        "  L1_distance = L1_layer([encoded_topred, encoded_pastlot])\n",
        "  print(L1_distance.shape)\n",
        "  print(price_input[:,i].shape)\n",
        "  price = tf.expand_dims(price_input[:,i], axis=1)\n",
        "  priceandfeature = tf.concat([L1_distance, price], axis=1)\n",
        "  priceandfeature = tf.expand_dims(priceandfeature, axis=1)\n",
        "\n",
        "\n",
        "  if i == 0:\n",
        "    lstm_input = priceandfeature\n",
        "  else:\n",
        "    lstm_input = tf.concat([lstm_input, priceandfeature], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "lstm = tf.keras.Sequential([\n",
        "                            #tf.keras.layers.LSTM(200, activation='relu', return_sequences=True, input_shape=(n, 128+1)),\n",
        "                            #tf.keras.layers.LSTM(100, activation='relu', return_sequences=True),\n",
        "                            #tf.keras.layers.LSTM(50, activation='relu', return_sequences=True),\n",
        "                            #tf.keras.layers.LSTM(25, activation='relu'),\n",
        "                            #tf.keras.layers.Dense(20, activation='relu'),\n",
        "                            #tf.keras.layers.Dense(10, activation='relu'),\n",
        "                            #tf.keras.layers.Dense(1)\n",
        "                            tf.keras.layers.LSTM(10, activation='relu', input_shape=(n, 128+1)),\n",
        "                            tf.keras.layers.Dense(1)\n",
        "                            #THIS VERSION IS FOR SINGLE LAYER LSTM; COMMENT UNCOMMENTED AND UNCOMMENT COMMENTED TO SWITCH\n",
        "])\n",
        "\n",
        "prediction = lstm(lstm_input)\n",
        "lstm_net = tf.keras.Model(inputs=[topred_input, lastn_input, price_input], outputs=prediction)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCrDB4QEODVU"
      },
      "source": [
        "lstm_net.compile(loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.MeanAbsolutePercentageError()], \n",
        "                 optimizer=keras.optimizers.Adam(learning_rate=.001))\n",
        "lstm_net.summary()\n",
        "\n",
        "history = lstm_net.fit([topred_train, lastn_train, price_train], label_train, epochs=8, steps_per_epoch=41)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQFD8WKwOmvE"
      },
      "source": [
        "lstm_net.evaluate([topred_test, lastn_test, price_test], label_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvhKIIRDPBBJ"
      },
      "source": [
        "##Example Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz2HsBSfy6Gp",
        "outputId": "c8669c40-7bc7-4096-8381-78be769f02bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lstm_net.predict([topred_test[0:1,:,:,:], lastn_test[0:1,:,:,:,:], price_test[0:1,:]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[157985.77]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hbib0HV_KHhE",
        "outputId": "8910eb44-d3ad-4899-a355-ae3654e6851d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(label_test[0:1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[105625.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44OykTT4Lfch"
      },
      "source": [
        "from PIL import Image"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_BCa17CLzM1",
        "outputId": "93a22915-6618-441d-bff1-fb9e38c2825b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(topred_test[0,:,:,:].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4vrOPNhKip2"
      },
      "source": [
        "image = Image.fromarray(topred_test[0,:,:,:], 'RGB')\n",
        "image.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}