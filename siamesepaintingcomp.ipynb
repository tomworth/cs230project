{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "siamesepaintingcomp.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNwP7O4PzQsRTKyHa0bjNn3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWHESq9kWeLW"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import pathlib\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import random\n",
        "\n",
        "np.set_printoptions(precision=4)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2468gGReAC7"
      },
      "source": [
        "### Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATGE_5YEWz7j",
        "outputId": "8582e49c-4ff0-407e-8602-0a9621c2e231",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyJkpr_VSE98"
      },
      "source": [
        "Create a dictionary in which keys are all the artists and values are all of the images by that artist:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNa1oGmweW9p",
        "outputId": "5786161d-d31f-488c-e30e-e7514ffe329f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "artistdict = {}\n",
        "\n",
        "with open('/content/drive/My Drive/train_info.csv', 'r') as csvfile:\n",
        "  table = csv.reader(csvfile)\n",
        "  c = 0\n",
        "  for row in table:\n",
        "    if c == 0:\n",
        "      c += 1\n",
        "      continue\n",
        "    if row[1] not in artistdict:\n",
        "      artistdict[row[1]] = []\n",
        "    artistdict[row[1]].append(row[0])\n",
        "    c += 1\n",
        "    \n",
        "print(c)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0t1bk8dSXR-"
      },
      "source": [
        "Create a balanced set of labeled image pairs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5OTVCw6AlIj",
        "outputId": "0f30e9eb-bdbc-4f19-f8c0-b4c399cfa16b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "datapoints = []\n",
        "badcount=0\n",
        "for artist in artistdict.keys():\n",
        "  paintings = artistdict[artist]\n",
        "  if len(paintings) < 31:\n",
        "    continue\n",
        "  for i in range(30):\n",
        "    left = paintings[i]\n",
        "    if left[0] != '9':\n",
        "      continue\n",
        "    for j in range(i+1, 30):\n",
        "      right = paintings[j]\n",
        "      if right[0] != '9':\n",
        "        continue\n",
        "      datapoints.append([left, right, 1])\n",
        "      while True:\n",
        "        otherartist = random.choice(list(artistdict))\n",
        "        if otherartist == artist:\n",
        "          continue\n",
        "        otherpainting = random.choice(artistdict[otherartist])\n",
        "        if otherpainting[0] != '9':\n",
        "          continue\n",
        "        break\n",
        "\n",
        "      datapoints.append([left, otherpainting, 0])\n",
        "\n",
        "random.shuffle(datapoints)\n",
        "\n",
        "print(len(datapoints))\n",
        "print(badcount)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6708\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIDYwfIGSd0L"
      },
      "source": [
        "Process the datapoints into numpy array format:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRG0dNuHQKKV",
        "outputId": "06b7d739-bba8-45ae-e304-c0415fc3108e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def names_to_images(datapoint):\n",
        "  leftimage = datapoint[0]\n",
        "  rightimage = datapoint[1]\n",
        "  label = datapoint[2]\n",
        "\n",
        "  leftfilename = '/content/drive/My Drive/train_9/' + leftimage\n",
        "  rightfilename = '/content/drive/My Drive/train_9/' + rightimage\n",
        "\n",
        "  leftimage = tf.io.read_file(leftfilename)\n",
        "  leftimage = tf.image.decode_jpeg(leftimage, try_recover_truncated=True)\n",
        "  leftimage = tf.image.convert_image_dtype(leftimage, tf.float32)\n",
        "  leftimage = tf.image.resize(leftimage, [224, 224])\n",
        "\n",
        "  rightimage = tf.io.read_file(rightfilename)\n",
        "  rightimage = tf.image.decode_jpeg(rightimage, try_recover_truncated=True)\n",
        "  rightimage = tf.image.convert_image_dtype(rightimage, tf.float32)\n",
        "  rightimage = tf.image.resize(rightimage, [224, 224])\n",
        "\n",
        "\n",
        "  return leftimage, rightimage, label\n",
        "\n",
        "m = len(datapoints)\n",
        "leftimages = np.empty((m, 224, 224, 3))\n",
        "rightimages = np.empty((m, 224, 224, 3))\n",
        "labels = np.empty((m))\n",
        "\n",
        "i=0\n",
        "print(len(datapoints))\n",
        "\n",
        "dataset_size = 1470\n",
        "\n",
        "for datapoint in datapoints:\n",
        "  leftimage, rightimage, label = names_to_images(datapoint)\n",
        "  if leftimage.shape[2] != 3 or rightimage.shape[2] != 3:\n",
        "    continue\n",
        "  leftimages[i,:,:,:] = leftimage[:,:,:]\n",
        "  rightimages[i,:,:,:] = rightimage[:,:,:]\n",
        "  labels[i] = label\n",
        "  i+=1\n",
        "  if i == dataset_size:\n",
        "    break\n",
        "\n",
        "\n",
        "#img_folder = pathlib.Path('/content/drive/My Drive/train_9')\n",
        "#image_count = len(list(img_folder.glob('*.jpg')))\n",
        "#print(image_count)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfWq6v1QSkty"
      },
      "source": [
        "Define train, val, and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoqIl1VAInFX",
        "outputId": "46af3f11-e42e-42cb-fe5d-52bb80a35a6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "#dataset = tf.data.Dataset.from_tensor_slices((leftimages[:dataset_size,:,:,:], rightimages[:dataset_size,:,:,:], labels[:dataset_size]))\n",
        "\n",
        "train_size = int(0.7 * dataset_size)\n",
        "val_size = int(0.15 * dataset_size)\n",
        "test_size = int(0.15 * dataset_size)\n",
        "#print(dataset)\n",
        "\n",
        "#train = dataset.take(train_size)\n",
        "#val = dataset.skip(train_size).take(val_size)\n",
        "#test = dataset.skip(train_size).skip(val_size)\n",
        "\n",
        "leftimg_train = leftimages[:train_size,:,:,:]\n",
        "leftimg_val = leftimages[train_size:train_size + val_size,:,:,:]\n",
        "leftimg_test = leftimages[train_size + val_size:,:,:,:]\n",
        "\n",
        "rightimg_train = rightimages[:train_size,:,:,:]\n",
        "rightimg_val = rightimages[train_size:train_size + val_size,:,:,:]\n",
        "rightimg_test = rightimages[train_size + val_size:,:,:,:]\n",
        "\n",
        "label_train = labels[:train_size]\n",
        "label_val = labels[train_size:train_size + val_size]\n",
        "label_test = labels[train_size + val_size:]\n",
        "\n",
        "\n",
        "\n",
        "print(leftimg_train.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1029, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DZ___aNeLYs"
      },
      "source": [
        "Creating Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RC-xvcgaPcW"
      },
      "source": [
        "input_shape = [224, 224, 3]\n",
        "left_input = tf.keras.Input(input_shape)\n",
        "right_input = tf.keras.Input(input_shape)\n",
        "\n",
        "restransfer = tf.keras.Sequential([\n",
        "                             hub.KerasLayer(\"https://tfhub.dev/tensorflow/resnet_50/feature_vector/1\", trainable=False),\n",
        "                             tf.keras.layers.Dense(800, activation=\"relu\", trainable=True),\n",
        "                             tf.keras.layers.Dense(128, activation=\"relu\", trainable=True)\n",
        "\n",
        "]) # inputs size (None, 224, 224, 3) ; outputs size (128)\n",
        "\n",
        "encoded_l = restransfer(left_input)\n",
        "encoded_r = restransfer(right_input)\n",
        "\n",
        "L1_layer = tf.keras.layers.Lambda(lambda tensors:tf.math.abs(tensors[0] - tensors[1]))\n",
        "L1_distance = L1_layer([encoded_l, encoded_r])\n",
        "\n",
        "prediction = tf.keras.layers.Dense(1, activation=\"sigmoid\", trainable=True)(L1_distance)\n",
        "siamese_net = tf.keras.Model(inputs=[left_input, right_input], outputs=prediction)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDEOOAEpSqIv"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyUgeOswd8fX",
        "outputId": "537fbf7d-20b8-461d-f1fc-667d95d69bae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "siamese_net.compile(loss=\"binary_crossentropy\", metrics=['acc'], optimizer='adam')\n",
        "siamese_net.summary()\n",
        "history = siamese_net.fit([leftimg_train, rightimg_train], label_train, epochs=8)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, 128)          25302880    input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 128)          0           sequential_1[0][0]               \n",
            "                                                                 sequential_1[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            129         lambda_1[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 25,303,009\n",
            "Trainable params: 1,741,857\n",
            "Non-trainable params: 23,561,152\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/8\n",
            "33/33 [==============================] - 7s 205ms/step - loss: 0.7374 - acc: 0.6035\n",
            "Epoch 2/8\n",
            "33/33 [==============================] - 7s 210ms/step - loss: 0.3190 - acc: 0.8669\n",
            "Epoch 3/8\n",
            "33/33 [==============================] - 7s 212ms/step - loss: 0.1508 - acc: 0.9553\n",
            "Epoch 4/8\n",
            "33/33 [==============================] - 7s 209ms/step - loss: 0.0500 - acc: 0.9864\n",
            "Epoch 5/8\n",
            "33/33 [==============================] - 7s 206ms/step - loss: 0.0268 - acc: 0.9961\n",
            "Epoch 6/8\n",
            "33/33 [==============================] - 7s 203ms/step - loss: 0.0190 - acc: 0.9981\n",
            "Epoch 7/8\n",
            "33/33 [==============================] - 7s 201ms/step - loss: 0.0058 - acc: 1.0000\n",
            "Epoch 8/8\n",
            "33/33 [==============================] - 7s 201ms/step - loss: 0.0033 - acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc2fHNsXSsal"
      },
      "source": [
        "Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLFd3vQ96vPT",
        "outputId": "261b728e-ba08-4302-9022-73b9e44ebe04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "siamese_net.evaluate([leftimg_val, rightimg_val], label_val)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 2s 306ms/step - loss: 0.7986 - acc: 0.7045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7985625267028809, 0.7045454382896423]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPgUeRHwceHP"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    }
  ]
}